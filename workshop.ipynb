{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 1,
   "metadata": {},
=======
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
>>>>>>> Stashed changes
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission_file(predictions, model_name):\n",
    "    num_preds = len(predictions)\n",
    "    \n",
    "    if num_preds != 3926:\n",
    "        print(\"Number of predictions not equal to number of test observations!\")\n",
    "    \n",
    "    pd.DataFrame({\n",
    "        \"Prediction\" : predictions,\n",
    "        \"Id\" : range(1, num_preds + 1)\n",
    "    }).to_csv(model_name + \".csv\", index=False)\n",
    "    \n",
    "def accuracy(predictions, truth):\n",
    "    return np.mean(predictions == truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data and split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 3,
   "metadata": {},
=======
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
>>>>>>> Stashed changes
   "outputs": [],
   "source": [
    "# note: these datasets are slightly modified from the provided data\n",
    "# the train set includes the \"activity\" column, and both datasets have column names\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# FOR THE SAKE OF THE WORKSHOP: USE A SMALLER TRAINING SET SO THINGS RUN FASTER\n",
    "# FOR COMPETITION ENTRIES, REMOVE THIS SO YOU USE ALL THE TRAINING DATA\n",
    "train = train.loc[1:500, :]\n",
    "\n",
    "y = train[\"activity\"]\n",
    "X = train.iloc[:, train.columns != \"activity\"]\n",
    "\n",
    "# could split the data manually if you wanted:\n",
    "\n",
    "# msk = np.random.rand(len(train)) < 0.8\n",
    "\n",
    "# X_train = X[msk]\n",
    "# y_train = y[msk]\n",
    "# X_val = X[~msk]\n",
    "# y_val = y[~msk]\n",
    "\n",
    "# or use provided code\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models with different hyperparameters on the training set and evaluate on the validation set"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 4,
   "metadata": {},
=======
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
>>>>>>> Stashed changes
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "k: 5 gives validation accuracy: 0.83\n",
      "k: 10 gives validation accuracy: 0.78\n",
      "k: 15 gives validation accuracy: 0.83\n"
=======
      "k: 5 gives validation accuracy: 0.89\n",
      "k: 10 gives validation accuracy: 0.88\n",
      "k: 15 gives validation accuracy: 0.88\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "for k in [5, 10, 15]:\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    preds = knn.predict(X_val)\n",
    "    \n",
    "    report = \"k: \" + str(k) + \" gives validation accuracy: \" + str(accuracy(preds, y_val))\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the best value of K is 5. In practice, we want to do this for a bunch of train/validation splits, so we use cross-validation. In practice, it's also better to search for the best k by picking k randomly. Here's some code that automatically searches for the best k using cross validation."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 5,
   "metadata": {},
=======
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
>>>>>>> Stashed changes
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
<<<<<<< Updated upstream
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_neighbors': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000F647DEA908>},\n",
=======
       "          fit_params={}, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_neighbors': <scipy.stats._distn_infrastructure.rv_frozen object at 0x105e7e668>},\n",
>>>>>>> Stashed changes
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 5,
=======
     "execution_count": 33,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick k randomly in the range [1, 30]\n",
    "# note that for the competition there are a number of other useful hyperparameters worth exploring\n",
    "# in particular the precise metric, and whether votes are weighed by distance\n",
    "param_dist = {\n",
    "    'n_neighbors': sp_randint(1, 31),\n",
    "}\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier()\n",
    "\n",
    "# now try 10 random k and save the best\n",
    "clf_rs = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                            n_iter=10, n_jobs = -1)\n",
    "\n",
    "# now clf_rs is just a KNN model with the best value of k automatically selected\n",
    "# give the randomized search the entire training set, it'll do cross validation internally\n",
    "clf_rs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the results of the cross-validated search for k. Also assess performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.081339</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.892998</td>\n",
       "      <td>19</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.778443</td>\n",
       "      <td>0.882883</td>\n",
       "      <td>0.784431</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.895210</td>\n",
       "      <td>9.798072e-07</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022669</td>\n",
       "      <td>0.094673</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.900997</td>\n",
       "      <td>14</td>\n",
       "      <td>{'n_neighbors': 14}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.906907</td>\n",
       "      <td>0.772455</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.904192</td>\n",
       "      <td>3.772031e-03</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>0.006533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019677</td>\n",
       "      <td>0.095047</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.871992</td>\n",
       "      <td>22</td>\n",
       "      <td>{'n_neighbors': 22}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.796407</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.880240</td>\n",
       "      <td>4.690441e-04</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.036114</td>\n",
       "      <td>0.018127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021682</td>\n",
       "      <td>0.098070</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.894994</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.897898</td>\n",
       "      <td>0.772455</td>\n",
       "      <td>0.885886</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.901198</td>\n",
       "      <td>4.499520e-03</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.035409</td>\n",
       "      <td>0.006580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020348</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.918997</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.772455</td>\n",
       "      <td>0.933934</td>\n",
       "      <td>0.784431</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.922156</td>\n",
       "      <td>9.435275e-04</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.029408</td>\n",
       "      <td>0.013669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.024017</td>\n",
       "      <td>0.098069</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.877983</td>\n",
       "      <td>25</td>\n",
       "      <td>{'n_neighbors': 25}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772455</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.895210</td>\n",
       "      <td>5.103061e-03</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.012724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.020681</td>\n",
       "      <td>0.097070</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.947001</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.820359</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.778443</td>\n",
       "      <td>0.948949</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.946108</td>\n",
       "      <td>4.708084e-04</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.042475</td>\n",
       "      <td>0.001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.020681</td>\n",
       "      <td>0.095735</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.913995</td>\n",
       "      <td>12</td>\n",
       "      <td>{'n_neighbors': 12}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.921922</td>\n",
       "      <td>0.754491</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.692771</td>\n",
       "      <td>0.919162</td>\n",
       "      <td>4.718778e-04</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.044844</td>\n",
       "      <td>0.009327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.024351</td>\n",
       "      <td>0.100738</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.894994</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.897898</td>\n",
       "      <td>0.772455</td>\n",
       "      <td>0.885886</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.901198</td>\n",
       "      <td>6.132872e-03</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>0.035409</td>\n",
       "      <td>0.006580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.020681</td>\n",
       "      <td>0.092402</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.931006</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.927928</td>\n",
       "      <td>0.712575</td>\n",
       "      <td>0.939940</td>\n",
       "      <td>0.692771</td>\n",
       "      <td>0.925150</td>\n",
       "      <td>9.429656e-04</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.050494</td>\n",
       "      <td>0.006418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.016001         0.081339            0.766          0.892998   \n",
       "1       0.022669         0.094673            0.762          0.900997   \n",
       "2       0.019677         0.095047            0.774          0.871992   \n",
       "3       0.021682         0.098070            0.764          0.894994   \n",
       "4       0.020348         0.093400            0.758          0.918997   \n",
       "5       0.024017         0.098069            0.780          0.877983   \n",
       "6       0.020681         0.097070            0.772          0.947001   \n",
       "7       0.020681         0.095735            0.750          0.913995   \n",
       "8       0.024351         0.100738            0.764          0.894994   \n",
       "9       0.020681         0.092402            0.738          0.931006   \n",
       "\n",
       "  param_n_neighbors               params  rank_test_score  split0_test_score  \\\n",
       "0                19  {'n_neighbors': 19}                4           0.778443   \n",
       "1                14  {'n_neighbors': 14}                7           0.802395   \n",
       "2                22  {'n_neighbors': 22}                2           0.796407   \n",
       "3                16  {'n_neighbors': 16}                5           0.802395   \n",
       "4                11  {'n_neighbors': 11}                8           0.772455   \n",
       "5                25  {'n_neighbors': 25}                1           0.772455   \n",
       "6                 5   {'n_neighbors': 5}                3           0.820359   \n",
       "7                12  {'n_neighbors': 12}                9           0.802395   \n",
       "8                16  {'n_neighbors': 16}                5           0.802395   \n",
       "9                 4   {'n_neighbors': 4}               10           0.808383   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.882883           0.784431            0.900901   \n",
       "1            0.906907           0.772455            0.891892   \n",
       "2            0.846847           0.802395            0.888889   \n",
       "3            0.897898           0.772455            0.885886   \n",
       "4            0.933934           0.784431            0.900901   \n",
       "5            0.864865           0.808383            0.873874   \n",
       "6            0.945946           0.778443            0.948949   \n",
       "7            0.921922           0.754491            0.900901   \n",
       "8            0.897898           0.772455            0.885886   \n",
       "9            0.927928           0.712575            0.939940   \n",
       "\n",
       "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.734940            0.895210  9.798072e-07        0.013598   \n",
       "1           0.710843            0.904192  3.772031e-03        0.001886   \n",
       "2           0.722892            0.880240  4.690441e-04        0.002152   \n",
       "3           0.716867            0.901198  4.499520e-03        0.005720   \n",
       "4           0.716867            0.922156  9.435275e-04        0.002056   \n",
       "5           0.759036            0.895210  5.103061e-03        0.003562   \n",
       "6           0.716867            0.946108  4.708084e-04        0.002948   \n",
       "7           0.692771            0.919162  4.718778e-04        0.002496   \n",
       "8           0.716867            0.901198  6.132872e-03        0.004646   \n",
       "9           0.692771            0.925150  9.429656e-04        0.003095   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.022033         0.007520  \n",
       "1        0.038084         0.006533  \n",
       "2        0.036114         0.018127  \n",
       "3        0.035409         0.006580  \n",
       "4        0.029408         0.013669  \n",
       "5        0.020833         0.012724  \n",
       "6        0.042475         0.001379  \n",
       "7        0.044844         0.009327  \n",
       "8        0.035409         0.006580  \n",
       "9        0.050494         0.006418  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf_rs.cv_results_)"
=======
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.021781         0.096011            0.770          0.932001   \n",
      "1       0.019304         0.092941            0.762          0.900997   \n",
      "2       0.016900         0.094966            0.758          0.918997   \n",
      "3       0.018884         0.095232            0.758          0.913992   \n",
      "4       0.017575         0.091926            0.762          0.900994   \n",
      "5       0.017843         0.098186            0.768          0.875984   \n",
      "6       0.016488         0.095880            0.762          0.900994   \n",
      "7       0.018032         0.093920            0.772          0.869966   \n",
      "8       0.014131         0.091796            0.772          0.947001   \n",
      "9       0.014726         0.070209            0.738          0.931006   \n",
      "\n",
      "  param_n_neighbors               params  rank_test_score  split0_test_score  \\\n",
      "0                 7   {'n_neighbors': 7}                3           0.802395   \n",
      "1                14  {'n_neighbors': 14}                5           0.802395   \n",
      "2                11  {'n_neighbors': 11}                8           0.772455   \n",
      "3                10  {'n_neighbors': 10}                8           0.796407   \n",
      "4                17  {'n_neighbors': 17}                5           0.808383   \n",
      "5                24  {'n_neighbors': 24}                4           0.784431   \n",
      "6                17  {'n_neighbors': 17}                5           0.808383   \n",
      "7                28  {'n_neighbors': 28}                1           0.760479   \n",
      "8                 5   {'n_neighbors': 5}                1           0.820359   \n",
      "9                 4   {'n_neighbors': 4}               10           0.808383   \n",
      "\n",
      "   split0_train_score  split1_test_score  split1_train_score  \\\n",
      "0            0.927928           0.784431            0.936937   \n",
      "1            0.906907           0.772455            0.891892   \n",
      "2            0.933934           0.784431            0.900901   \n",
      "3            0.912913           0.772455            0.906907   \n",
      "4            0.903904           0.766467            0.891892   \n",
      "5            0.858859           0.790419            0.876877   \n",
      "6            0.903904           0.766467            0.891892   \n",
      "7            0.849850           0.796407            0.855856   \n",
      "8            0.945946           0.778443            0.948949   \n",
      "9            0.927928           0.712575            0.939940   \n",
      "\n",
      "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
      "0           0.722892            0.931138      0.004705        0.002471   \n",
      "1           0.710843            0.904192      0.005762        0.000213   \n",
      "2           0.716867            0.922156      0.001261        0.001719   \n",
      "3           0.704819            0.922156      0.002908        0.000997   \n",
      "4           0.710843            0.907186      0.001115        0.000920   \n",
      "5           0.728916            0.892216      0.005769        0.005546   \n",
      "6           0.710843            0.907186      0.002112        0.011886   \n",
      "7           0.759036            0.904192      0.000621        0.009075   \n",
      "8           0.716867            0.946108      0.002180        0.016401   \n",
      "9           0.692771            0.925150      0.000906        0.011594   \n",
      "\n",
      "   std_test_score  std_train_score  \n",
      "0        0.034012         0.003728  \n",
      "1        0.038084         0.006533  \n",
      "2        0.029408         0.013669  \n",
      "3        0.038748         0.006272  \n",
      "4        0.039926         0.006574  \n",
      "5        0.027662         0.013632  \n",
      "6        0.039926         0.006574  \n",
      "7        0.017294         0.024325  \n",
      "8        0.042475         0.001379  \n",
      "9        0.050494         0.006418  \n"
     ]
    }
   ],
   "source": [
    "knn_cv_results = pd.DataFrame(clf_rs.cv_results_)\n",
    "print(pd.DataFrame(clf_rs.cv_results_))"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the cross-validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGhNJREFUeJzt3X+UXGV9x/H3JxsQEhLAwxqVsFmwqZp6Kto1Wg+1Aoqg\nIhVbCwZ/IJ4tDSD2l1LXHmltLFLs8QcIXRUFuxRFjUaPBcG2YFur2WAQEvGQxiQkoklEDWFVyObb\nP+4dGdbd2Wcme2fuzv28zpkze59778z3noH7zfPjPo8iAjMzs+nM6XQAZmY2OzhhmJlZEicMMzNL\n4oRhZmZJnDDMzCyJE4aZmSVxwjAzsyROGGZmlsQJw8zMksztdAAz6aijjor+/v5Oh2FmNmusW7du\nd0T0phzbVQmjv7+f0dHRTodhZjZrSNqaeqybpMzMLIkThpmZJSk0YUg6VdL3JG2SdMkk+4+UtFrS\ndyR9S9Kz6vZtkXS3pPWS3M5kZtZhhfVhSOoBrgJeCmwH1kpaExEb6w57J7A+Il4t6Rn58SfX7T8x\nInYXFaOZmaUrsoaxHNgUEZsj4hHgRuCMCccsA/4dICLuBfolLSowJjMza1GRCeNo4P667e15Wb27\ngDMBJC0HlgCL830B3CZpnaTBqb5E0qCkUUmju3btmrHgpzIyAv39MGdO9j4yUvhXmpmVQqc7vS8D\njpC0HrgI+DYwnu87ISKOB04DLpD0osk+ICKGI2IgIgZ6e5OGErdsZAQGB2HrVojI3gcHnTTMrBqK\nTBg7gGPqthfnZb8SEXsi4tw8MbwB6AU25/t25O87gdVkTVwdNTQEY2OPLxsby8rNzLpdkQljLbBU\n0rGSDgbOAtbUHyDpiHwfwFuAOyJij6T5khbkx8wHTgHuKTDWJNu2NVduZtZNChslFRH7JF0I3AL0\nANdGxAZJ5+f7rwGeCVwnKYANwHn56YuA1ZJqMd4QETcXFWuqvr6sGWqycjOzblfo1CAR8RXgKxPK\nrqn7+xvAb05y3mbg2UXG1opVq7I+i/pmqXnzsnIzs27X6U7vWWXFChgehiVLQMreh4ezcjOzbtdV\nkw+2w4oVThBmVk2uYZiZWRInDDMzS+KEYWZmSZwwzMwsiROGmZklccIwM7MkThgl5VlxzaxsKp8w\nynhj9qy4ZlZGlU4YZb0xe1ZcMyujSieMst6YPSuumZVRpRNGWW/MU81+61lxzayTKp0wynpjXrUq\nmwW3nmfFNbNOq3TCKOuN2bPimlkZVXq22toNeGgoa4bq68uSRRluzJ4V18zKptIJA3xjNjNLVekm\nKTMzS+eEYWZmSZwwzMwsiROGmZklccKwwpVxvi4za17lR0lZsWrzddWmYKnN1wUenWY227iGYYUq\n63xdZta8aROGpIskHdmOYKz7lHW+LjNrXkoNYxGwVtJnJJ0qSUUHZeXVbH9EWefrMrPmTZswIuJd\nwFLg48CbgPskvVfS0wqOzUqmlfVDyjpfl5k1L6kPIyIC+GH+2gccCXxW0uUFxmYl00p/hCdSNOse\nynJBgwOki4E3ALuBjwFfiIhHJc0B7ouI0tQ0BgYGYnR0tNNhdK05c7KaxUQS7N/f/njM7MBJWhcR\nAynHpgyrfSJwZkRsrS+MiP2SXtlKgDY79fVlzVCTlZtZ90tpkvo34MHahqSFkp4PEBHfLSowKx/3\nR5hVW0rCuBrYW7e9Ny+zinF/hFm1pTRJKeo6OvKmKD8hXlFeP8SsulJqGJslvVXSQfnrYmBz0YGZ\nmVm5pCSM84EXAjuA7cDzgcEigzIzs/KZtmkpInYCZ7UhFjMzK7FpE4akQ4DzgN8CDqmVR8SbC4zL\nzMxKJqVJ6lPAk4GXAbcDi4GHigzKzMzKJyVh/EZE/A3wcERcB7yCrB9jWvlkhd+TtEnSJZPsP1LS\naknfkfQtSc9KPdfsQJV1YaeVK2Hu3Gzo8ty52bZZGaQkjEfz95/mN/TDgSdNd5KkHuAq4DRgGXC2\npGUTDnsnsD4ifpts+pEPNnGuWctamUixHVauhKuvhvHxbHt8PNt20rAySEkYw/l6GO8C1gAbgfcl\nnLcc2BQRmyPiEeBG4IwJxywD/h0gIu4F+iUtSjzXrGVlXdhpeLi5crN2atjpnU8wuCcifgLcARzX\nxGcfDdxft10bklvvLuBM4OuSlgNLyPpIUs41a1lZF3aq1SxSy83aqWENIyL2A28v8PsvA46QtB64\nCPg20NT/GpIGJY1KGt21a1cRMVoXKuvCTj09zZWbtVNKk9Rtkv5S0jGSnlh7JZy3AzimbntxXvYr\nEbEnIs6NiOPJ+jB6yZ4in/bcus8YjoiBiBjo7e1NCMusvBMpDk7xSOxU5WbtlDIn1B/n7xfUlQXT\nN0+tBZZKOpbsZn8W8Lr6AyQdAYzl/RRvAe6IiD2Spj3X7EDU5sMaGsqaofr6smTR6XmyPvKR7H14\nOGuG6unJkkWt3KyTpl1A6YA+XHo58AGgB7g2IlZJOh8gIq6R9LvAdWQJaANwXt5fMum5032fF1Ay\nM2tOMwsopay494bJyiPi+hZiK5QThplZc2Z6xb3n1f19CHAycCdQuoRhZmbFSZl88KL67bzf4cbC\nIjIzs1JKGSU10cPAsTMdiJmZlVvKbLVfIuuUhizBLAM+U2RQZmZWPil9GFfU/b0P2BoR2wuKx8zM\nSiolYWwDHoiIXwBIOlRSf0RsKTQyMzMrlZQ+jJuA/XXb43mZmZlVSErCmJs/iQ1A/vfBxYVkZmZl\nlJIwdkl6VW1D0hnA7uJCMjOzMkrpwzgfGJF0Zb69nWyiQDMzq5CUB/f+D3iBpMPy7b2FR2VmZqUz\nbZOUpPdKOiIi9kbE3nwd7r9vR3BmZlYeKX0Yp0XET2sb+WyyLy8uJDMzK6OUhNEj6Qm1DUmHAk9o\ncLyZmXWhlIQxAnxN0nmSzgNuxTPVmtksNTIC/f0wZ072PjLS6Yhmj5RO7/dJugt4SV70noi4pdiw\nzMxm3shItoLh2Fi2vXXrY8vfdnq1xdmg6RX3JJ0AnB0RF0x7cJt5ASUza6S/P0sSEy1ZAlu2tDua\ncpjpBZSQ9BzgbOC1wPeBz7cenplZZ2zb1ly5Pd6UCUPSb5IlibPJnuz+NFmN5MQ2xWZmNqP6+iav\nYfT1tT+W2ahRp/e9wEnAKyPihIj4MNnEg2Zms9KqVTBv3uPL5s3Lym16jRLGmcADwH9I+qikkwG1\nJywzs5m3YgUMD2d9FlL2Pjw8ezu82z3ia9pOb0nzgTPImqZOIhtSuzoivlpsaM1zp7eZVcXEEV+Q\n1ZaaTYDNdHpP+xxGRDwcETdExOnAYuDbwDvSwzEzs5k2NPT4ZAHZ9tBQcd+Z8uDer0TETyJiOCJO\nLiogMzObXidGfDWVMMzMrBymGtlV5IgvJwwzs1moEyO+nDDMzGahToz4mvZJb0lnAu8DnkQ2rFZA\nRMTC4sIyM7PprFjR3iHBKVODXA6cHhHfLToYMzMrr5QmqR85WZiZWUoNY1TSp4EvAL+sFUaEJyA0\nM6uQlISxEBgDTqkrCzxjrZlZpaQsoHRuOwIxM7Nym7YPQ9JiSasl7cxfn5O0uB3BmZlZeaR0en8C\nWAM8NX99KS8zM7MKSUkYvRHxiYjYl78+CfQWHJeZmZVMSsL4saRzJPXkr3OAHxcdmJmZlUtKwngz\n2VrePyRbUOkPAXeEm5lVTMooqa3Aq1r5cEmnAh8EeoCPRcRlE/YfDvwL0JfHckVEfCLftwV4iGxZ\n2H2pC3yYmVkxpkwYkt4eEZdL+jDZcxePExFvbfTBknqAq4CXAtuBtZLWRMTGusMuADZGxOmSeoHv\nSRqJiEfy/SdGxO4mr8nMzArQqIZRmw6k1TVPlwObImIzgKQbyZZ6rU8YASyQJOAw4EFgX4vfZ2Zm\nBZoyYUTEl/I/xyLipvp9kv4o4bOPBu6v294OPH/CMVeSDdn9AbAA+OOI2F8LAbhN0jjwzxExnPCd\nZmZWkJRO779OLGvFy4D1ZM93HA9cKak2bfoJEXE8cBpwgaQXTfYBkgYljUoa3bVr1wyFZWZmEzXq\nwzgNeDlwtKQP1e1aSFqz0Q7gmLrtxXlZvXOByyIigE2Svg88A/hWROwAiIidklaTNXHdMfFL8prH\nMMDAwMCv9bWYmdnMaFTD+AFZ/8UvgHV1rzVkNYPprAWWSjpW0sHAWfm59bYBJwNIWgQ8Hdgsab6k\nBXn5fLKJD+9JvSgzM5t5jfow7gLuknRDRDza7AdHxD5JFwK3kA2rvTYiNkg6P99/DfAe4JOS7iZb\nye8dEbFb0nHA6qwvnLnADRFxc7MxmJnZzFHWGtTgAGkp8A/AMuCQWnlEHFdsaM0bGBiI0dFWB3WZ\nmVWPpHWpz7mlTj54NVm/xYnA9WQP25mZWYWkJIxDI+JrZLWRrRFxKfCKYsMyM7OySVlx75eS5gD3\n5X0SO8gesjMzswpJqWFcDMwD3gr8DnAO8MYigzIzs/JJmXxwbf7nXjxLrZlZZaUs0XqrpCPqto+U\ndEuxYZmZWdmkNEkdFRE/rW1ExE+AJxUXkpmZlVFKwtgvqa+2IWkJk0x3bmZm3S1llNQQ8F+Sbid7\nGvv3gMFCozIzs9JJ6fS+WdJzgRfkRW/zokZmZtUzZZOUpGfk788lW0L1B/mrLy8zM7MKaVTD+HOy\npqf3T7IvgJMKicjMzEqpUcK4NX8/r7bMqpmZVVejUVK1VfU+245AzMys3BrVMH4s6avAsZImLnxE\nRLyquLDMzKxsGiWMVwDPBT7F5P0YZmZWIY1W3HsE+F9JL4yIXW2MyczMSmjKhCHpAxHxNuBaSb/2\nZLebpMzMqqVRk9Sn8vcr2hGImZmVW6MmqXX5++21MklHAsdExHfaEJuZmZVIyvTm/ylpoaQnAncC\nH5X0T8WHZmZmZZIyW+3hEbEHOBO4PiKeD7yk2LDMzKxsUhLGXElPAV4LfLngeMzMrKRSEsbfAbcA\nmyJiraTjgPuKDcvMzMomZXrzm4Cb6rY3A68pMigzMyuflE7vy/NO74MkfU3SLknntCM4MzMrj5Qm\nqVPyTu9XAluA3wD+qsigzMysfJI6vfP3VwA3RcTPCozHzMxKKmVN7y9Luhf4OfCnknqBXxQblpmZ\nlc20NYyIuAR4ITAQEY8CDwNnFB2YmZmVS0oNA+CpwEskHVJXdn0B8ZiZWUlNmzAkvRt4MbAM+Apw\nGvBfOGGYmVVKSqf3HwInAz+MiHOBZwOHFxqVmZmVTkrC+HlE7Af2SVoI7ASOKTYsMzMrm5Q+jFFJ\nRwAfBdYBe4FvFBqVmZmVTsrUICvzP6+RdDOw0OthmJlVT6MlWp/baF9E3FlMSGZmVkaNahjvb7Av\ngJNmOBYzMyuxRku0ntjOQMzMrNymHCUl6RxJr5+k/PWSXpfy4ZJOlfQ9SZskXTLJ/sMlfUnSXZI2\nSDo39VwzM2uvRsNqLwJWT1L+eeAvpvtgST3AVWQP+i0Dzpa0bMJhFwAbI+LZZA8Hvl/SwYnnmplZ\nGzVKGAdFxN6JhRHxMHBQwmcvJ1ulb3NEPALcyK/PQRXAAkkCDgMeBPYlnmtmZm3UKGEcKmn+xEJJ\nC4CDEz77aOD+uu3teVm9K4FnAj8A7gYuzh8STDm3Fs+gpFFJo7t27UoIy8zMWtEoYXwc+KykJbUC\nSf1k/9r/+Ax9/8uA9WSTGx4PXJk/TZ4sIoYjYiAiBnp7e2coLDMzm6jRKKkrJO0F7pB0WF68F7gs\nIq5O+OwdPH4KkcV5Wb1z888LYJOk7wPPSDzXzMzaqOGT3hFxDdkT3gvy7Yea+Oy1wFJJx5Ld7M8C\nJo6u2kY2seHXJS0Cng5sBn6acK6ZmbVR0noYTSaK2jn7JF0I3AL0ANdGxAZJ5+f7rwHeA3xS0t2A\ngHdExG6Ayc5tNgYzM5s5ylqDusPAwECMjo52Ogwzs1lD0rqIGEg5NmV6czMzs7QmKUkvBPrrj48I\nr7hnZlYhKUu0fgp4Gtnw1/G8OPASrWZmlZJSwxgAlkU3dXaYmVnTUvow7gGeXHQgZmZWbik1jKOA\njZK+BfyyVhgRryosKjMzK52UhHFp0UGYmVn5pazpfXs7AjEzs3Kbtg9D0gskrZW0V9IjksYl7WlH\ncGZmVh4pnd5XAmcD9wGHAm8hW9zIzMwqJOlJ74jYBPRExHhEfAI4tdiwzMysbFI6vcckHQysl3Q5\n8ACeUsTMrHJSbvyvz4+7EHiYbJ2K1xQZlJmZlU/KKKmtkg4FnhIRf9uGmMzMrIRSRkmdTjaP1M35\n9vGS1hQdmJmZlUtKk9SlwHKyVfCIiPXAsQXGZGZmJZSSMB6NiJ9NKPNEhGZmFZMySmqDpNcBPZKW\nAm8F/qfYsMzMrGxSahgXAb9FNvHgvwJ7gLcVGVSpjYxAfz/MmZO9j4x0OiIzq6o2349SRkmNAUP5\nq9pGRmBwEMbGsu2tW7NtgBUrOheXmVVPB+5HmmpdpOlGQpVxevOBgYEYHR0t7gv6+7MfZaIlS2DL\nlpn9rpERGBqCbdugrw9WrXJSMrPHzND9SNK6iBhIObZRDeN3gfvJmqG+CSg5gm61bVtz5a1yTcbM\nptOu+1GdRn0YTwbeCTwL+CDwUmB3RNxe2SnP+/qaK2/V0NBjyaJmbCwrN7MD0y39kO26H9WZMmHk\nEw3eHBFvBF4AbAL+U9KFhUVTdqtWwbx5jy+bNy8rn0kd+JeDWSXUau9bt0LEY7X32Zg02nU/qtNw\nlJSkJ0g6E/gX4ALgQ8DqwqIpuxUrYHg4ayOUsvfh4ZlvJurAvxzMKqGbau/tuh/VadTpfT1Zc9RX\ngBsj4p7CopghhXd6t8vEPgzI/uVQ8H8MZl1vzpysZjGRBPv3tz+eEmim07tRDeMcYClwMfA/kvbk\nr4e84l7BOvAvB7NKcO39gDTqw5gTEQvy18K614KIWNjOICtpxYpsaNz+/dm7k8XMK2vn58qVMHdu\n9o+FuXOzbZsZHWj37yZeCMmqqaydnytXwtVXw/h4tj0+nm07acwM194PyJR9GLNR1/RhWPHa+RBm\nM+bOfSxZ1OvpgX372h+Pdb2Z6sMw615lHbo8WbJoVG7WRk4Y1pxW2v3L2FdQ1s7Pnp7mys3ayAnD\n0rXS7l/WvoKydn7WpoBJLTdrI/dhWLpW2v3L2lcA5Z3gceXKrCN2fDyrWQwOwkc+0umorEs104fh\nhGHpWnnoyQ9KmZWaO72tGK20+5e1r8DMmuaEYelaafcva1+BmTXNCcPStfLQkx+UMusahfZhSDqV\nbC2NHuBjEXHZhP1/BdTuHHOBZwK9EfGgpC3AQ8A4sC+ljc19GGZmzZmpFfcONIge4CqyhZe2A2sl\nrYmIjbVjIuIfgX/Mjz8d+LOIeLDuY06MiN1FxWhmZumKbJJaDmyKiM0R8QhwI3BGg+PPJlsO1szM\nSqjIhHE02ZrgNdvzsl8jaR5wKvC5uuIAbpO0TpKfWjIz67DCmqSadDrw3xOao06IiB2SngTcKune\niLhj4ol5MhkE6PNQTTOzwhRZw9gBHFO3vTgvm8xZTGiOiogd+ftOsmVhl092YkQMR8RARAz09vYe\ncNBmZja5IhPGWmCppGMlHUyWFNZMPEjS4cDvA1+sK5svaUHtb+AUoPRLxJqZdbPCmqQiYp+kC4Fb\nyIbVXhsRGySdn++/Jj/01cBXI+LhutMXAasl1WK8ISJuLipWMzObnueSMjOrMM8lZWZmM84Jw8zM\nkjhhmJlZEieMMi4famZWQmV5cK8zasuHjo1l27XlQ8GzqZqZTVDtGsbQ0GPJomZsLCs3M7PHqXbC\n2LatuXIzswqrdsLw8qFmZsmqnTC8fKiZWbJqJwwvH2pmlqzao6QgSw5OEGZm06p2DcPMzJI5YZiZ\nWRInDDMzS+KEYWZmSZwwzMwsSVctoCRpF7C1TV93FLC7Td9VRlW+/ipfO1T7+rvx2pdERG/KgV2V\nMNpJ0mjqKlXdqMrXX+Vrh2pff5WvHdwkZWZmiZwwzMwsiRNG64Y7HUCHVfn6q3ztUO3rr/K1uw/D\nzMzSuIZhZmZJnDBaIGmLpLslrZc02ul4iibpWkk7Jd1TV/ZESbdKui9/P7KTMRZlimu/VNKO/Pdf\nL+nlnYyxKJKOkfQfkjZK2iDp4ry863/7Btdeid9+Km6SaoGkLcBARHTbeOxJSXoRsBe4PiKelZdd\nDjwYEZdJugQ4MiLe0ck4izDFtV8K7I2IKzoZW9EkPQV4SkTcKWkBsA74A+BNdPlv3+DaX0sFfvup\nuIZh04qIO4AHJxSfAVyX/30d2f9MXWeKa6+EiHggIu7M/34I+C5wNBX47Rtce6U5YbQmgNskrZM0\n2OlgOmRRRDyQ//1DYFEng+mAiyR9J2+y6rommYkk9QPPAb5JxX77CdcOFfvt6zlhtOaEiDgeOA24\nIG+2qKzI2jWr1LZ5NXAccDzwAPD+zoZTLEmHAZ8D3hYRe+r3dftvP8m1V+q3n8gJowURsSN/3wms\nBpZ3NqKO+FHezltr793Z4XjaJiJ+FBHjEbEf+Chd/PtLOojshjkSEZ/Piyvx20927VX67SfjhNEk\nSfPzTjAkzQdOAe5pfFZXWgO8Mf/7jcAXOxhLW9VulrlX06W/vyQBHwe+GxH/VLer63/7qa69Kr/9\nVDxKqkmSjiOrVUC2JvoNEbGqgyEVTtK/Ai8mm6nzR8C7gS8AnwH6yGYIfm1EdF3n8BTX/mKyJokA\ntgB/Utem3zUknQB8Hbgb2J8Xv5OsLb+rf/sG1342Ffjtp+KEYWZmSdwkZWZmSZwwzMwsiROGmZkl\nccIwM7MkThhmZpbECcOsQJL662e6NZvNnDDMzCyJE4ZZm0g6TtK3JT2v07GYtWJupwMwqwJJTwdu\nBN4UEXd1Oh6zVjhhmBWvl2y+pTMjYmOngzFrlZukzIr3M2AbcEKnAzE7EK5hmBXvEbKZTW+RtDci\nbuh0QGatcMIwa4OIeFjSK4Fb86SxptMxmTXLs9WamVkS92GYmVkSJwwzM0vihGFmZkmcMMzMLIkT\nhpmZJXHCMDOzJE4YZmaWxAnDzMyS/D9Q9lEH8Kg6PwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11563d5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(knn_cv_results['param_n_neighbors'], knn_cv_results['mean_test_score'], 'ro')\n",
    "plt.plot(knn_cv_results['param_n_neighbors'], knn_cv_results['mean_train_score'], 'bo')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Mean Classification Accuracy') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, predict on the text set and save the "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 7,
   "metadata": {},
=======
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
>>>>>>> Stashed changes
   "outputs": [],
   "source": [
    "preds = clf_rs.predict(test)\n",
    "create_submission_file(preds, \"knn_tuned_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some sample code for grid search on a support vector machine for classification"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 8,
   "metadata": {},
=======
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
>>>>>>> Stashed changes
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kernel': ['rbf'], 'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}, {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in practice you will want to try much broader ranges of hyperparameters than this\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "svm_clf = GridSearchCV(SVC(), tuned_parameters)\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
<<<<<<< Updated upstream
   "cell_type": "markdown",
   "metadata": {},
=======
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "Again we check how well we did"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 10,
   "metadata": {},
=======
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
>>>>>>> Stashed changes
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.040859</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.776013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.682635</td>\n",
       "      <td>0.780781</td>\n",
       "      <td>0.700599</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.763473</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.010837</td>\n",
       "      <td>0.048246</td>\n",
       "      <td>0.008951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134634</td>\n",
       "      <td>0.038352</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.379997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.383234</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.383234</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.367470</td>\n",
       "      <td>0.383234</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.007424</td>\n",
       "      <td>0.002289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061332</td>\n",
       "      <td>0.037352</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.992007</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.856287</td>\n",
       "      <td>0.996997</td>\n",
       "      <td>0.964072</td>\n",
       "      <td>0.993994</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.985030</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.046353</td>\n",
       "      <td>0.005084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.048084</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.813002</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.688623</td>\n",
       "      <td>0.819820</td>\n",
       "      <td>0.754491</td>\n",
       "      <td>0.807808</td>\n",
       "      <td>0.620482</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.054683</td>\n",
       "      <td>0.005037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063181</td>\n",
       "      <td>0.035648</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.868263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.028595</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.062504</td>\n",
       "      <td>0.026046</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.856287</td>\n",
       "      <td>0.993994</td>\n",
       "      <td>0.964072</td>\n",
       "      <td>0.993994</td>\n",
       "      <td>0.885542</td>\n",
       "      <td>0.985030</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>0.045549</td>\n",
       "      <td>0.004226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.062501</td>\n",
       "      <td>0.031244</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.868263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.028595</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.062716</td>\n",
       "      <td>0.024967</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014239</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.055084</td>\n",
       "      <td>0.025470</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear', 'C': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005964</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.060589</td>\n",
       "      <td>0.037033</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear', 'C': 10}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.057813</td>\n",
       "      <td>0.024567</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear', 'C': 100}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.052698</td>\n",
       "      <td>0.028659</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear', 'C': 1000}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0        0.090130         0.040859            0.658          0.776013       1   \n",
       "1        0.134634         0.038352            0.378          0.379997       1   \n",
       "2        0.061332         0.037352            0.900          0.992007      10   \n",
       "3        0.072917         0.048084            0.688          0.813002      10   \n",
       "4        0.063181         0.035648            0.908          1.000000     100   \n",
       "5        0.062504         0.026046            0.902          0.991006     100   \n",
       "6        0.062501         0.031244            0.908          1.000000    1000   \n",
       "7        0.062716         0.024967            0.908          1.000000    1000   \n",
       "8        0.055084         0.025470            0.908          1.000000       1   \n",
       "9        0.060589         0.037033            0.908          1.000000      10   \n",
       "10       0.057813         0.024567            0.908          1.000000     100   \n",
       "11       0.052698         0.028659            0.908          1.000000    1000   \n",
       "\n",
       "   param_gamma param_kernel                                         params  \\\n",
       "0        0.001          rbf      {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}   \n",
       "1       0.0001          rbf     {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}   \n",
       "2        0.001          rbf     {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}   \n",
       "3       0.0001          rbf    {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}   \n",
       "4        0.001          rbf    {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}   \n",
       "5       0.0001          rbf   {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}   \n",
       "6        0.001          rbf   {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}   \n",
       "7       0.0001          rbf  {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}   \n",
       "8          NaN       linear                   {'kernel': 'linear', 'C': 1}   \n",
       "9          NaN       linear                  {'kernel': 'linear', 'C': 10}   \n",
       "10         NaN       linear                 {'kernel': 'linear', 'C': 100}   \n",
       "11         NaN       linear                {'kernel': 'linear', 'C': 1000}   \n",
       "\n",
       "    rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0                11           0.682635            0.780781           0.700599   \n",
       "1                12           0.383234            0.378378           0.383234   \n",
       "2                 9           0.856287            0.996997           0.964072   \n",
       "3                10           0.688623            0.819820           0.754491   \n",
       "4                 1           0.868263            1.000000           0.934132   \n",
       "5                 8           0.856287            0.993994           0.964072   \n",
       "6                 1           0.868263            1.000000           0.934132   \n",
       "7                 1           0.862275            1.000000           0.934132   \n",
       "8                 1           0.862275            1.000000           0.934132   \n",
       "9                 1           0.862275            1.000000           0.934132   \n",
       "10                1           0.862275            1.000000           0.934132   \n",
       "11                1           0.862275            1.000000           0.934132   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0             0.783784           0.590361            0.763473      0.015493   \n",
       "1             0.378378           0.367470            0.383234      0.007092   \n",
       "2             0.993994           0.879518            0.985030      0.003768   \n",
       "3             0.807808           0.620482            0.811377      0.007365   \n",
       "4             1.000000           0.921687            1.000000      0.006948   \n",
       "5             0.993994           0.885542            0.985030      0.000002   \n",
       "6             1.000000           0.921687            1.000000      0.000015   \n",
       "7             1.000000           0.927711            1.000000      0.014239   \n",
       "8             1.000000           0.927711            1.000000      0.005964   \n",
       "9             1.000000           0.927711            1.000000      0.008241   \n",
       "10            1.000000           0.927711            1.000000      0.001304   \n",
       "11            1.000000           0.927711            1.000000      0.002863   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.010837        0.048246         0.008951  \n",
       "1         0.005303        0.007424         0.002289  \n",
       "2         0.005017        0.046353         0.005084  \n",
       "3         0.001724        0.054683         0.005037  \n",
       "4         0.006724        0.028595         0.000000  \n",
       "5         0.007372        0.045549         0.004226  \n",
       "6         0.000008        0.028595         0.000000  \n",
       "7         0.006737        0.032486         0.000000  \n",
       "8         0.006996        0.032486         0.000000  \n",
       "9         0.005193        0.032486         0.000000  \n",
       "10        0.006375        0.032486         0.000000  \n",
       "11        0.002458        0.032486         0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(svm_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 11,
   "metadata": {},
=======
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
>>>>>>> Stashed changes
   "outputs": [],
   "source": [
    "preds = svm_clf.predict(test)\n",
    "create_submission_file(preds, \"svm_tuned_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
